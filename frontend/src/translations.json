{
  "ko": {
    "header.settings": "설정",
    "header.login": "로그인",
    "header.selectModel": "모델 선택",
    "settings.title": "모델 설정",
    "settings.acceleration": "하드웨어 가속",
    "settings.accelerator": "가속기 백엔드 (참고용)",
    "settings.gpuLayers": "GPU 오프로드 레이어 (-ngl)",
    "settings.inference": "기본 추론 설정",
    "settings.sampling": "샘플링",
    "settings.penalties": "페널티",
    "settings.mirostat": "Mirostat 샘플링",
    "settings.maxTokens": "최대 토큰 (n_predict)",
    "settings.contextSize": "컨텍스트 크기 (n_ctx)",
    "settings.temperature": "온도",
    "settings.topK": "Top-K",
    "settings.topP": "Top-P",
    "settings.minP": "Min-P",
    "settings.tfsZ": "Tail Free Sampling (tfs_z)",
    "settings.typicalP": "Typical-P",
    "settings.repeatPenalty": "반복 페널티",
    "settings.repeatLastN": "마지막 N개 토큰 페널티",
    "settings.penalizeNL": "개행 문자 페널티",
    "settings.dryMultiplier": "DRY 페널티 강도 (Multiplier)",
    "settings.dryBase": "DRY 페널티 베이스 (Base)",
    "settings.dryAllowedLength": "DRY 허용 반복 길이",
    "settings.dryPenaltyLastN": "DRY 적용 범위 (Last N)",
    "settings.presencePenalty": "Presence Penalty",
    "settings.frequencyPenalty": "Frequency Penalty",
    "settings.mirostatMode": "Mirostat 모드",
    "settings.mirostatTau": "Mirostat Tau (목표 엔트로피)",
    "settings.mirostatEta": "Mirostat Eta (학습률)",
    "settings.save": "저장",
    "settings.close": "취소",
    "settings.modelPath": "모델 경로",
    "settings.findModel": "모델 찾기",
    "settings.modelList": "모델 목록",
    "settings.addNewModel": "새 모델 추가",
    "settings.modelName": "모델 이름",
    "settings.deleteModel": "삭제",
    "settings.noModelSelected": "편집할 모델을 선택하거나 새 모델을 추가하세요.",
    "accelerator.auto": "자동 감지",
    "accelerator.mps": "Metal (Apple Silicon)",
    "accelerator.cuda": "CUDA (NVIDIA)",
    "accelerator.opencl": "OpenCL",
    "chat.logsTitle": "서버 로그",
    "descriptions.title": "설정 설명",
    "descriptions.accelerator": "사용할 하드웨어 가속 백엔드를 선택합니다. 이 옵션은 llama.cpp가 해당 기능을 지원하도록 빌드된 경우에만 의미가 있습니다. '자동 감지'로 두면 서버가 최적의 백엔드를 선택합니다.",
    "descriptions.gpuLayers": "GPU로 오프로드할 모델 레이어의 수입니다. 0은 CPU만 사용함을 의미합니다. GPU의 VRAM 용량에 따라 적절한 값을 설정해야 합니다. '-1' 또는 매우 큰 숫자를 입력하면 가능한 모든 레이어를 오프로드합니다.",
    "descriptions.maxTokens": "최대 토큰 (n_predict): 한 번의 응답에서 모델이 새로 생성할 수 있는 최대 토큰 수입니다. 컨텍스트 크기(n_ctx)가 전체 대화(프롬프트+응답)에 대해 사용 가능한 토큰 수라면, n_predict는 그 중에서 '이번에 새로 생성할 토큰'의 상한입니다. 값을 크게 하면 더 긴 응답을 생성할 수 있지만, 컨텍스트 한계에 더 빨리 도달할 수 있습니다.",
    "descriptions.contextSize": "컨텍스트 크기 (Context Size): 모델이 한 번에 처리할 수 있는 최대 토큰 수입니다. 이 값은 모델이 얼마나 긴 대화나 문서를 '기억'할 수 있는지를 결정합니다. 모델이 지원하는 최대 크기 내에서 설정해야 합니다. (예: 2048, 4096, 8192)",
    "descriptions.temperature": "온도 (Temperature): 값이 높을수록 더 창의적이고 무작위적인 텍스트를 생성합니다. 낮은 값은 더 예측 가능하고 일관된 텍스트를 만듭니다. (일반적 범위: 0.7 ~ 1.0)",
    "descriptions.topK": "Top-K 샘플링: 다음 토큰을 예측할 때 가장 확률이 높은 K개의 후보 중에서만 선택합니다. K가 작을수록 선택지가 제한됩니다. (일반적 범위: 40 ~ 50)",
    "descriptions.topP": "Top-P (Nucleus) 샘플링: 누적 확률이 P 이상인 최소한의 토큰 집합 중에서 다음 토큰을 선택합니다. 0.95는 상위 95% 확률을 가진 후보 중에서 선택함을 의미합니다.",
    "descriptions.minP": "Min-P 샘플링: Top-P와 유사하지만, 확률이 낮은 후보를 제거하는 최소 임계값을 설정합니다. (일반적 범위: 0.05 ~ 0.1)",
    "descriptions.tfsZ": "Tail Free Sampling (TFS): 확률 분포의 꼬리 부분(확률이 낮은 토큰들)을 동적으로 잘라내어 샘플링 품질을 향상시킵니다. 1.0은 비활성화를 의미합니다.",
    "descriptions.typicalP": "Typical-P 샘플링: 의미적으로 덜 적합한 토큰을 제거하여 더 자연스러운 텍스트를 생성하려는 샘플링 방식입니다. 1.0은 비활성화를 의미합니다.",
    "descriptions.repeatPenalty": "반복 페널티 (Repeat Penalty): 이전에 생성된 토큰이 다시 나타날 확률을 줄입니다. 1.0보다 큰 값을 사용하면 반복을 억제하는 데 도움이 됩니다. (일반적 범위: 1.1 ~ 1.2)",
    "descriptions.repeatLastN": "마지막 N개 토큰 페널티: `repeat_penalty`가 고려하는 토큰의 범위를 마지막 N개로 제한합니다. -1은 전체 컨텍스트를 의미합니다.",
    "descriptions.penalizeNL": "개행 문자 페널티: 모델이 생성하는 텍스트에 개행 문자(줄바꿈)가 너무 많이 포함되지 않도록 페널티를 부여합니다.",
    "descriptions.dryMultiplier": "DRY(Do Not Repeat Yourself) 페널티 강도: 반복되는 시퀀스에 적용할 페널티의 강도입니다. 0.0은 비활성화를 의미하며, 보통 0.8 정도의 값을 사용합니다.",
    "descriptions.dryBase": "DRY 페널티 베이스: 페널티 계산의 기저값입니다. 값이 클수록 반복에 대한 페널티가 지수적으로 증가합니다. (기본값: 1.75)",
    "descriptions.dryAllowedLength": "DRY 허용 반복 길이: 페널티를 적용하기 전에 허용하는 반복 토큰의 길이입니다. 이 값보다 긴 반복이 발생하면 페널티가 적용됩니다. (기본값: 2)",
    "descriptions.dryPenaltyLastN": "DRY 적용 범위: 마지막 N개의 토큰을 검사하여 반복을 찾습니다. -1은 전체 컨텍스트를 검사합니다.",
    "descriptions.presencePenalty": "Presence Penalty: 텍스트에 한 번이라도 나타난 토큰의 반복 가능성을 줄입니다. 새로운 주제에 대해 이야기하도록 유도할 때 유용합니다.",
    "descriptions.frequencyPenalty": "Frequency Penalty: 텍스트에 이미 나타난 빈도에 비례하여 토큰의 반복 가능성을 줄입니다. 같은 단어를 여러 번 사용하는 것을 더 강력하게 억제합니다.",
    "descriptions.mirostatMode": "Mirostat 샘플링 모드: 일정한 수준의 창의성(Perplexity)을 유지하도록 샘플링을 동적으로 조절합니다. 0은 비활성화, 1은 Mirostat, 2는 Mirostat v2를 의미합니다.",
    "descriptions.mirostatTau": "Mirostat Tau: Mirostat의 목표 창의성(Perplexity) 값입니다. 값이 높을수록 더 무작위적인 텍스트를 생성합니다. (v2 권장값: ~5.0)",
    "descriptions.mirostatEta": "Mirostat Eta: Mirostat의 학습률(learning rate)입니다. Tau 값에 얼마나 빨리 도달할지를 결정합니다. (v2 권장값: ~0.1)",
    "settings.debug": "디버깅",
    "settings.showSpecialTokens": "스페셜 토큰 표시",
    "descriptions.showSpecialTokens": "스페셜 토큰 표시: LLM 출력에서 스페셜 토큰(<|begin_of_text|>, <|eot_id|> 등)을 표시할지 여부를 설정합니다. 디버깅 용도로 사용됩니다.",
    "chat.send": "전송",
    "chat.clear": "초기화",
    "chat.placeholder": "메시지를 입력하세요...",
    "chat.welcome": "무엇을 도와드릴까요?",
    "infoPanel.title": "실시간 추론 설정",
    "infoPanel.modelName": "현재 모델",
    "infoPanel.description": "여기에 표시된 설정은 '설정' 페이지에서 수정할 수 있으며, 다음 채팅부터 적용됩니다."
  },
  "en": {
    "header.settings": "Settings",
    "header.login": "Login",
    "header.selectModel": "Select Model",
    "settings.title": "Model Settings",
    "settings.acceleration": "Hardware Acceleration",
    "settings.accelerator": "Accelerator Backend (Informational)",
    "settings.gpuLayers": "GPU Offload Layers (-ngl)",
    "settings.inference": "Basic Inference Settings",
    "settings.sampling": "Sampling",
    "settings.penalties": "Penalties",
    "settings.mirostat": "Mirostat Sampling",
    "settings.maxTokens": "Max Tokens (n_predict)",
    "settings.contextSize": "Context Size (n_ctx)",
    "settings.temperature": "Temperature",
    "settings.topK": "Top-K",
    "settings.topP": "Top-P",
    "settings.minP": "Min-P",
    "settings.tfsZ": "Tail Free Sampling (tfs_z)",
    "settings.typicalP": "Typical-P",
    "settings.repeatPenalty": "Repeat Penalty",
    "settings.repeatLastN": "Repeat Last N Tokens",
    "settings.penalizeNL": "Penalize Newlines",
    "settings.dryMultiplier": "DRY Multiplier",
    "settings.dryBase": "DRY Base",
    "settings.dryAllowedLength": "DRY Allowed Length",
    "settings.dryPenaltyLastN": "DRY Penalty Last N",
    "settings.presencePenalty": "Presence Penalty",
    "settings.frequencyPenalty": "Frequency Penalty",
    "settings.mirostatMode": "Mirostat Mode",
    "settings.mirostatTau": "Mirostat Tau (Target Entropy)",
    "settings.mirostatEta": "Mirostat Eta (Learning Rate)",
    "settings.save": "Save",
    "settings.close": "Cancel",
    "settings.modelPath": "Model Path",
    "settings.findModel": "Find Model",
    "settings.modelList": "Model List",
    "settings.addNewModel": "Add New Model",
    "settings.modelName": "Model Name",
    "settings.deleteModel": "Delete",
    "settings.noModelSelected": "Select a model to edit, or add a new one.",
    "accelerator.auto": "Auto Detect",
    "accelerator.mps": "Metal (Apple Silicon)",
    "accelerator.cuda": "CUDA (NVIDIA)",
    "accelerator.opencl": "OpenCL",
    "chat.logsTitle": "Server Logs",
    "descriptions.title": "Settings Descriptions",
    "descriptions.accelerator": "Select the hardware acceleration backend. This is only for reference, as the server will auto-detect the best available backend. Support depends on how llama.cpp was built.",
    "descriptions.gpuLayers": "Number of layers to offload to the GPU. 0 means CPU-only. Set an appropriate value based on your GPU's VRAM. Use '-1' or a very high number to offload all possible layers.",
    "descriptions.maxTokens": "Max Tokens (n_predict): The maximum number of new tokens the model is allowed to generate in a single response. While context size (n_ctx) limits the total tokens for prompt + response, n_predict controls only how many tokens to generate for this completion. Increasing this allows for longer answers, but may hit the context limit sooner.",
    "descriptions.contextSize": "Context Size: The maximum number of tokens the model can process at once. This determines how much of the conversation or document the model can 'remember'. (e.g., 2048, 4096, 8192).",
    "descriptions.temperature": "Temperature: Higher values (e.g., 1.0) produce more creative text. Lower values (e.g., 0.7) result in more predictable text.",
    "descriptions.topK": "Top-K Sampling: The model considers only the top K most likely tokens. A smaller K limits the choices (e.g., 40-50).",
    "descriptions.topP": "Top-P (Nucleus) Sampling: Selects from a minimal set of tokens whose cumulative probability exceeds P (e.g., 0.95).",
    "descriptions.minP": "Min-P Sampling: Sets a minimum probability threshold to discard low-probability candidates. (Typical range: 0.05-0.1).",
    "descriptions.tfsZ": "Tail Free Sampling (TFS): Dynamically cuts off the tail of the probability distribution. A value of 1.0 disables it.",
    "descriptions.typicalP": "Typical-P Sampling: A sampling method that tries to generate more natural-sounding text. A value of 1.0 disables it.",
    "descriptions.repeatPenalty": "Repeat Penalty: Reduces the likelihood of tokens that have already appeared. Values greater than 1.0 (e.g., 1.1-1.2) help suppress repetition.",
    "descriptions.repeatLastN": "Repeat Last N Tokens: Limits the scope of `repeat_penalty` to the last N tokens. A value of -1 means the entire context.",
    "descriptions.penalizeNL": "Penalize Newlines: Applies a penalty to the newline character, discouraging too many line breaks.",
    "descriptions.dryMultiplier": "DRY (Do Not Repeat Yourself) Multiplier: The strength of the penalty applied to repeated sequences. 0.0 disables it. Values around 0.8 are common.",
    "descriptions.dryBase": "DRY Base: The base value for penalty calculation. Higher values increase the penalty exponentially for repetitions. (Default: 1.75)",
    "descriptions.dryAllowedLength": "DRY Allowed Length: The length of repetition allowed before applying the penalty. Sequences longer than this will be penalized. (Default: 2)",
    "descriptions.dryPenaltyLastN": "DRY Penalty Last N: The number of recent tokens to scan for repetitions. -1 means the entire context.",
    "descriptions.presencePenalty": "Presence Penalty: Reduces the chance of repeating any token that has appeared at least once. Useful for encouraging new topics.",
    "descriptions.frequencyPenalty": "Frequency Penalty: Reduces the chance of repeating a token based on how frequently it has already appeared. More aggressive at preventing word loops.",
    "descriptions.mirostatMode": "Mirostat Sampling Mode: A sampling method that dynamically adjusts sampling to maintain a constant level of creativity (perplexity). 0=Disabled, 1=Mirostat, 2=Mirostat v2.",
    "descriptions.mirostatTau": "Mirostat Tau: The target perplexity for Mirostat. Higher values lead to more random text. (Recommended for v2: ~5.0)",
    "descriptions.mirostatEta": "Mirostat Eta: The learning rate for Mirostat, determining how quickly it adapts to reach the target Tau. (Recommended for v2: ~0.1)",
    "settings.debug": "Debug",
    "settings.showSpecialTokens": "Show Special Tokens",
    "descriptions.showSpecialTokens": "Show Special Tokens: Whether to display special tokens (<|begin_of_text|>, <|eot_id|>, etc.) in LLM output. Useful for debugging purposes.",
    "chat.send": "Send",
    "chat.clear": "Clear",
    "chat.placeholder": "Type a message...",
    "chat.welcome": "How can I help you?",
    "infoPanel.title": "Live Inference Settings",
    "infoPanel.modelName": "Current Model",
    "infoPanel.description": "The settings displayed here can be modified on the Settings page and will apply to the next chat."
  }
}

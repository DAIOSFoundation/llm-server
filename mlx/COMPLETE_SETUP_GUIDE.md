# DeepSeek-MoE-16b MLX ì™„ì „ ì„¤ì • ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ
C++ ì¶”ë¡  ì—”ì§„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ê²€ì¦ë˜ê³  í†µí•©ëœ ê¹¨ë—í•œ ëª¨ë¸ íŒŒì¼** í™•ë³´

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- Apple Silicon (M1/M2/M3/M4) Mac
- RAM: 16GB ì´ìƒ ê¶Œì¥
- VRAM: 4-bit ì–‘ìí™” ì‹œ ì•½ 9~10GB ì†Œìš”

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
- Python 3.9 ì´ìƒ
- pip (Python íŒ¨í‚¤ì§€ ê´€ë¦¬ì)

## ğŸš€ 1ë‹¨ê³„: ëª¨ë¸ ë³€í™˜ (ìë™í™” ìŠ¤í¬ë¦½íŠ¸)

### ì‹¤í–‰ ë°©ë²•

```bash
cd /Volumes/Transcend/Projects/llm-server/mlx
chmod +x setup_deepseek_mlx.sh
./setup_deepseek_mlx.sh
```

### ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…

1. **ê°€ìƒí™˜ê²½ ìƒì„±**: Python ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
2. **íŒ¨í‚¤ì§€ ì„¤ì¹˜**: mlx-lm, huggingface_hub ì„¤ì¹˜
3. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**: Hugging Faceì—ì„œ DeepSeek-MoE-16b-chat ìë™ ë‹¤ìš´ë¡œë“œ
4. **4-bit ì–‘ìí™”**: MLX í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° ì–‘ìí™”
5. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**: ë³€í™˜ëœ ëª¨ë¸ë¡œ ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸

### ì˜ˆìƒ ì†Œìš” ì‹œê°„
- ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë‹¤ë¦„ (ìˆ˜ì‹­ GB)
- ë³€í™˜ ë° ì–‘ìí™”: ì•½ 30ë¶„ ~ 1ì‹œê°„ (í•˜ë“œì›¨ì–´ ì„±ëŠ¥ì— ë”°ë¼ ë‹¤ë¦„)

## ğŸ§ª 2ë‹¨ê³„: Pythonìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸

### ì‹¤í–‰ ë°©ë²•

```bash
cd /Volumes/Transcend/Projects/llm-server/mlx
source venv/bin/activate  # ê°€ìƒí™˜ê²½ í™œì„±í™”
python chat_deepseek.py
```

### ì˜ˆìƒ ì¶œë ¥

```
Loading model from ./deepseek-16b-mlx-q4...
Model loaded. Start chatting! (Type 'quit' to exit)
--------------------------------------------------
User: ì•ˆë…•í•˜ì„¸ìš”
Assistant: ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
```

## ğŸ”§ 3ë‹¨ê³„: C++ í”„ë¡œì íŠ¸ì— ëª¨ë¸ ì—°ê²°

### ëª¨ë¸ íŒŒì¼ ë³µì‚¬

ë³€í™˜ëœ ëª¨ë¸ì„ C++ í”„ë¡œì íŠ¸ì˜ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬:

```bash
# ë³€í™˜ëœ ëª¨ë¸ í™•ì¸
ls -lh ./deepseek-16b-mlx-q4/

# C++ í”„ë¡œì íŠ¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
cp -r ./deepseek-16b-mlx-q4/* ./models/deepseek-moe-16b-chat-mlx-q4_0/
```

### í•„ìˆ˜ íŒŒì¼ í™•ì¸

ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:

```
models/deepseek-moe-16b-chat-mlx-q4_0/
â”œâ”€â”€ config.json              # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ tokenizer.json           # í† í¬ë‚˜ì´ì € ì„¤ì •
â”œâ”€â”€ tokenizer_config.json    # í† í¬ë‚˜ì´ì € ì¶”ê°€ ì„¤ì •
â”œâ”€â”€ weights.safetensors      # í†µí•©ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ (ë˜ëŠ” ì—¬ëŸ¬ íŒŒì¼)
â””â”€â”€ model.safetensors.index.json  # (ì—¬ëŸ¬ íŒŒì¼ì¸ ê²½ìš°)
```

### ê°€ì¤‘ì¹˜ ê²€ì¦

```python
import mlx.core as mx
import json

# Config í™•ì¸
with open("models/deepseek-moe-16b-chat-mlx-q4_0/config.json") as f:
    config = json.load(f)

expected_dim = config["hidden_size"]  # 2048

# Weight í™•ì¸
weights = mx.load("models/deepseek-moe-16b-chat-mlx-q4_0/weights.safetensors")
q_proj = weights["model.layers.0.self_attn.q_proj.weight"]

print(f"Expected: ({expected_dim}, {expected_dim})")
print(f"Actual: {q_proj.shape}")

if q_proj.shape == (expected_dim, expected_dim):
    print("âœ… ëª¨ë¸ íŒŒì¼ ì •ìƒ! C++ ì—”ì§„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
else:
    print("âŒ ëª¨ë¸ íŒŒì¼ ë¬¸ì œ ìˆìŒ - ì¬ë³€í™˜ í•„ìš”")
```

## âœ… 4ë‹¨ê³„: C++ ì„œë²„ í…ŒìŠ¤íŠ¸

ëª¨ë¸ íŒŒì¼ì´ ì¤€ë¹„ë˜ë©´ C++ ì„œë²„ë¥¼ ì‹¤í–‰:

```bash
cd /Volumes/Transcend/Projects/llm-server/mlx
npm run build
node test-server-temp.js
```

### ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤

```
[MLX] LoadSafetensors: Loading weights...
[MLX] q_proj shape: (2048, 2048) - Verified âœ…
[MLX] o_proj shape: (2048, 2048) - Verified âœ…
[MLX] No MLP weights detected in Attention block âœ…
[MLX] Server started on port 8081
```

## ğŸ” ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: "q_proj shape mismatch" ì—ëŸ¬

**ì›ì¸**: ëª¨ë¸ íŒŒì¼ì´ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ìƒ¤ë”©ëœ ìƒíƒœ

**í•´ê²°**:
1. `setup_deepseek_mlx.sh` ìŠ¤í¬ë¦½íŠ¸ë¡œ ì¬ë³€í™˜
2. `weights.safetensors` íŒŒì¼ í¬ê¸° í™•ì¸ (ì•½ 8-10GBì—¬ì•¼ í•¨)
3. ìœ„ì˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ë¡œ shape í™•ì¸

### ë¬¸ì œ: "MLP weight detected in Attention" ì—ëŸ¬

**ì›ì¸**: ê°€ì¤‘ì¹˜ í‚¤ ë§¤í•‘ ì˜¤ë¥˜

**í•´ê²°**: C++ ì½”ë“œì˜ ì—„ê²©í•œ ê²€ì¦ ë¡œì§ì´ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŒ. ëª¨ë¸ íŒŒì¼ì´ ì •ìƒì´ë©´ ë°œìƒí•˜ì§€ ì•ŠìŒ.

### ë¬¸ì œ: ë³€í™˜ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼

**ì›ì¸**: í•˜ë“œì›¨ì–´ ì„±ëŠ¥ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì†ë„

**í•´ê²°**:
- ë„¤íŠ¸ì›Œí¬ê°€ ëŠë¦¬ë©´ ì‚¬ì „ì— ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ
- ë³€í™˜ì€ í•œ ë²ˆë§Œ ìˆ˜í–‰í•˜ë©´ ë˜ë¯€ë¡œ ê¸°ë‹¤ë¦¼

## ğŸ“Š íŒŒì¼ í¬ê¸° ê°€ì´ë“œ

ì •ìƒì ì¸ ëª¨ë¸ íŒŒì¼ í¬ê¸°:

- **16B ëª¨ë¸ 4-bit ì–‘ìí™”**: ì•½ 8-10GB
- **ë‹¨ì¼ weights.safetensors**: 8-10GB (í†µí•©ëœ ê²½ìš°)
- **ì—¬ëŸ¬ íŒŒì¼ë¡œ ë¶„í• **: ê° íŒŒì¼ì´ 2-4GB (ì •ìƒ)

âš ï¸ **ê²½ê³ **: íŒŒì¼ì´ 1-2GBë¼ë©´ ë¶ˆì™„ì „í•œ íŒŒì¼ì…ë‹ˆë‹¤.

## ğŸ‰ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `setup_deepseek_mlx.sh` ì‹¤í–‰ ì™„ë£Œ
- [ ] `chat_deepseek.py` í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ê°€ì¤‘ì¹˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ í†µê³¼ (q_proj: 2048x2048)
- [ ] C++ ì„œë²„ ì •ìƒ ì‹œì‘
- [ ] ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ

## ğŸ’¡ ì¶”ê°€ íŒ

### ê°€ìƒí™˜ê²½ ì¬ì‚¬ìš©

```bash
# ë‹¤ìŒì— ì‚¬ìš©í•  ë•Œ
cd /Volumes/Transcend/Projects/llm-server/mlx
source venv/bin/activate
python chat_deepseek.py
```

### ëª¨ë¸ ê²½ë¡œ ë³€ê²½

`chat_deepseek.py`ì˜ `model_path` ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥

### ë°°ì¹˜ ë³€í™˜

ì—¬ëŸ¬ ëª¨ë¸ì„ í•œ ë²ˆì— ë³€í™˜í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ë°˜ë³µ ì‹¤í–‰

---

**ì‘ì„±ì¼**: 2024
**ìƒíƒœ**: âœ… ì™„ì „í•œ ì„¤ì • ê°€ì´ë“œ


=== DeepSeek-MoE-16b MLX 4-bit 변환 및 설정 시작 ===
[INFO] 가상환경(venv)을 생성합니다...
[INFO] MLX 및 Hugging Face 패키지 설치 중...
Requirement already satisfied: pip in ./venv/lib/python3.8/site-packages (23.0.1)
Collecting pip
  Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.0.1
    Uninstalling pip-23.0.1:
      Successfully uninstalled pip-23.0.1
Successfully installed pip-25.0.1
Collecting mlx-lm
  Downloading mlx_lm-0.29.1-py3-none-any.whl.metadata (9.4 kB)
Collecting huggingface_hub
  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
INFO: pip is looking at multiple versions of mlx-lm to determine which version is compatible with other requirements. This could take a while.
Collecting mlx-lm
  Using cached mlx_lm-0.28.4-py3-none-any.whl.metadata (9.4 kB)
  Using cached mlx_lm-0.28.3-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.28.2-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.28.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.28.0-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.27.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.27.0-py3-none-any.whl.metadata (10 kB)
INFO: pip is still looking at multiple versions of mlx-lm to determine which version is compatible with other requirements. This could take a while.
  Using cached mlx_lm-0.26.4-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.26.3-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.26.2-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.26.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.26.0-py3-none-any.whl.metadata (10 kB)
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Using cached mlx_lm-0.25.3-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.25.2-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.25.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.25.0-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.24.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.24.0-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.23.2-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.23.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.23.0-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.22.5-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.22.4-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.22.3-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.22.2-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.22.1-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.22.0-py3-none-any.whl.metadata (10 kB)
  Using cached mlx_lm-0.21.5-py3-none-any.whl.metadata (9.9 kB)
  Using cached mlx_lm-0.21.4-py3-none-any.whl.metadata (9.4 kB)
  Using cached mlx_lm-0.21.3-py3-none-any.whl.metadata (9.4 kB)
  Using cached mlx_lm-0.21.2-py3-none-any.whl.metadata (9.4 kB)
  Using cached mlx_lm-0.21.1-py3-none-any.whl.metadata (9.4 kB)
  Using cached mlx_lm-0.21.0-py3-none-any.whl.metadata (9.4 kB)
  Using cached mlx_lm-0.20.6-py3-none-any.whl.metadata (9.2 kB)
  Using cached mlx_lm-0.20.5-py3-none-any.whl.metadata (9.2 kB)
  Using cached mlx_lm-0.20.4-py3-none-any.whl.metadata (9.2 kB)
  Using cached mlx_lm-0.20.3-py3-none-any.whl.metadata (9.2 kB)
  Using cached mlx_lm-0.20.2-py3-none-any.whl.metadata (9.2 kB)
  Using cached mlx_lm-0.20.1-py3-none-any.whl.metadata (9.0 kB)
  Using cached mlx_lm-0.19.3-py3-none-any.whl.metadata (8.9 kB)
  Using cached mlx_lm-0.19.2-py3-none-any.whl.metadata (8.1 kB)
Collecting mlx>=0.17.0 (from mlx-lm)
  Using cached mlx-0.18.1-cp38-cp38-macosx_14_0_arm64.whl.metadata (5.1 kB)
Collecting numpy (from mlx-lm)
  Downloading numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.6 kB)
Collecting transformers>=4.39.3 (from transformers[sentencepiece]>=4.39.3->mlx-lm)
  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)
Collecting protobuf (from mlx-lm)
  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)
Collecting pyyaml (from mlx-lm)
  Using cached PyYAML-6.0.3-cp38-cp38-macosx_15_0_arm64.whl
Collecting jinja2 (from mlx-lm)
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting filelock (from huggingface_hub)
  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec>=2023.5.0 (from huggingface_hub)
  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)
Collecting packaging>=20.9 (from huggingface_hub)
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting requests (from huggingface_hub)
  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)
Collecting tqdm>=4.42.1 (from huggingface_hub)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)
  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)
Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)
  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)
Collecting regex!=2019.12.17 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)
  Downloading regex-2024.11.6-cp38-cp38-macosx_11_0_arm64.whl.metadata (40 kB)
Collecting tokenizers<0.21,>=0.20 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)
  Downloading tokenizers-0.20.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.7 kB)
Collecting safetensors>=0.4.1 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)
  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)
Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.39.3->mlx-lm)
  Using cached sentencepiece-0.2.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (7.7 kB)
Collecting MarkupSafe>=2.0 (from jinja2->mlx-lm)
  Downloading MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_universal2.whl.metadata (3.0 kB)
Collecting charset_normalizer<4,>=2 (from requests->huggingface_hub)
  Using cached charset_normalizer-3.4.4-cp38-cp38-macosx_10_9_universal2.whl.metadata (37 kB)
Collecting idna<4,>=2.5 (from requests->huggingface_hub)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub)
  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->huggingface_hub)
  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Using cached mlx_lm-0.19.2-py3-none-any.whl (115 kB)
Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 17.0 MB/s eta 0:00:00

Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)
Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)
Using cached mlx-0.18.1-cp38-cp38-macosx_14_0_arm64.whl (21.3 MB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 48.3 MB/s eta 0:00:00

Downloading numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl (13.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 54.1 MB/s eta 0:00:00

Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)
Using cached filelock-3.16.1-py3-none-any.whl (16 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)
Using cached requests-2.32.4-py3-none-any.whl (64 kB)
Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached charset_normalizer-3.4.4-cp38-cp38-macosx_10_9_universal2.whl (198 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Downloading MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_universal2.whl (18 kB)
Downloading regex-2024.11.6-cp38-cp38-macosx_11_0_arm64.whl (284 kB)
Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)
Using cached sentencepiece-0.2.0-cp38-cp38-macosx_11_0_arm64.whl (1.2 MB)
Downloading tokenizers-0.20.3-cp38-cp38-macosx_11_0_arm64.whl (2.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 51.8 MB/s eta 0:00:00

Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)
Installing collected packages: sentencepiece, urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, protobuf, packaging, numpy, mlx, MarkupSafe, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, huggingface_hub, tokenizers, transformers, mlx-lm
Successfully installed MarkupSafe-2.1.5 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.16.1 fsspec-2025.3.0 hf-xet-1.2.0 huggingface_hub-0.36.0 idna-3.11 jinja2-3.1.6 mlx-0.18.1 mlx-lm-0.19.2 numpy-1.24.4 packaging-25.0 protobuf-5.29.5 pyyaml-6.0.3 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 sentencepiece-0.2.0 tokenizers-0.20.3 tqdm-4.67.1 transformers-4.46.3 typing-extensions-4.13.2 urllib3-2.2.3
[INFO] 변환(Quantization) 시작... (시간이 소요됩니다)
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
[INFO] Loading
Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]Fetching 14 files: 100%|██████████| 14/14 [00:00<00:00, 292140.58it/s]
[INFO] Quantizing
=== [TEST] 변환된 모델 테스트 ===
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
==========
Prompt: <｜begin▁of▁sentence｜>User: Hello, introduce yourself.

Assistant:
Hello! I'm an AI language model, trained to assist with a wide range of tasks, such as answering questions, generating text, and providing information on various topics. How can I assist you today?
==========
Prompt: 13 tokens, 7.229 tokens-per-sec
Generation: 43 tokens, 83.363 tokens-per-sec
Peak memory: 8.644 GB
=== 완료되었습니다! ===
변환된 모델 위치: ./deepseek-16b-mlx-q4
생성된 weights.safetensors 파일이 깨끗한 4bit 파일입니다.

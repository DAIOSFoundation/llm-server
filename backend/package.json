{
  "name": "llm-server-backend",
  "version": "1.0.0",
  "description": "llama.cpp 기반 LLM 서버",
  "main": "server.js",
  "type": "module",
  "scripts": {
    "start": "node server.js",
    "dev": "node --watch server.js"
  },
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5",
    "ws": "^8.14.2",
    "node-llama-cpp": "^2.7.0"
  },
  "devDependencies": {
    "@types/node": "^20.10.0"
  }
}

